% % unix('mplayer tv:// -tv driver=v4l2:width=140:height=140:device=/dev/video1 -frames 1 -vo jpeg');

I_collection = {};
I_collection{1} = imread('simpler/02.jpg');
I_collection{2} = imread('simpler/03.jpg');
I_collection{3} = imread('simpler/04.jpg');
I_collection{4} = imread('simpler/05.jpg');
I_collection{5} = imread('simpler/06.jpg');
I_collection{6} = imread('simpler/07.jpg');
I_collection{7} = imread('simpler/08.jpg');
I_collection{8} = imread('simpler/09.jpg');
% I_collection{9} = imread('simpler/10.jpg');

I_training = {};
I_training{1} = imread('simpler/training/02.jpg');
I_training{2} = imread('simpler/training/03.jpg');
I_training{3} = imread('simpler/training/04.jpg');
I_training{4} = imread('simpler/training/05.jpg');
I_training{5} = imread('simpler/training/06.jpg');
I_training{6} = imread('simpler/training/07.jpg');
I_training{7} = imread('simpler/training/08.jpg');
I_training{8} = imread('simpler/training/09.jpg');
% I_training{9} = imread('simpler/training/10.jpg');

obj_vectors = [];

obj_classes = [];

obj_images = {};

for i=1:11
    obj_images{i} = {};
end

for j=1:size(I_collection, 2)

    [final_images, class_images] = image_segmentation(I_collection{j}, I_training{j}, 6, 2);

    for i=1:size(final_images, 2)

        % figure(i + j *11922)
        % colormap(gray)
        % imagesc(final_images{i})

        % figure(i + j *119212)
        % colormap(gray)
        % imagesc(class_images{i})

        class_type = get_class_from_training_image(class_images{i});
        obj_classes(size(obj_vectors, 1) + 1, 1) = class_type;

        [obj_vectors(size(obj_vectors, 1) + 1, :), feature_image] = get_object_feature_vector(final_images{i}, j * 101 + i);

        if(class_type > 0)
            obj_images{class_type}{size(obj_images{class_type}, 2) + 1} = feature_image;
        else
            obj_images{11}{size(obj_images{11}, 2) + 1} = feature_image;
        end

    end
end

indx_nan = find(sum(isnan(obj_vectors ), 2) > 0);
obj_vectors(indx_nan,:) = [];
obj_classes(indx_nan,:) = [];
indx_neg = find(obj_classes < 0);
obj_vectors(indx_neg,:) = [];
obj_classes(indx_neg,:) = [];

data_m = [obj_vectors, obj_classes];

% % divide data into train/test
[data_train, data_test] = create_train_test_data(data_m, 10, 0.75);

nb_model = fitNaiveBayes(data_train(:, 1:(size(data_train, 2) - 1)), data_train(:, size(data_train, 2)));
pred_classes = nb_model.predict(data_test(:, 1:(size(data_test, 2) - 1)));

accuracy = error_analysis(pred_classes, data_test(:, size(data_test, 2)));

con_m = confusion_matrix(pred_classes, data_test(:, size(data_test, 2)), 10)

scatter3(obj_vectors(:, 1), obj_vectors(:, 2), obj_vectors(:, 3), 12, obj_classes);
xlabel('circle comparison');
ylabel('holes in object');
set(get(gca, 'ZLabel'), 'String', 'colour hash');


% for c=1:10
% 
%     for i=1:size(obj_images{c}, 2)
%         figure(c * 20 + i)
%         colormap(gray)
%         imagesc(obj_images{c}{i})
%     end
% 
% end
